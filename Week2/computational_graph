digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139717091823264 [label="
 (1, 11)" fillcolor=darkolivegreen1]
	139716867808016 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 300)
mat1_sym_strides:       (300, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (300, 11)
mat2_sym_strides:       (1, 300)"]
	139716867808304 -> 139716867808016
	139716867885952 [label="output_layer.bias
 (11)" fillcolor=lightblue]
	139716867885952 -> 139716867808304
	139716867808304 [label=AccumulateGrad]
	139716867808208 -> 139716867808016
	139716867808208 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	139716867808160 -> 139716867808208
	139716867808160 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 300)
mat1_sym_strides:       (300, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (300, 300)
mat2_sym_strides:       (1, 300)"]
	139716867808448 -> 139716867808160
	139716867885792 [label="layer2.bias
 (300)" fillcolor=lightblue]
	139716867885792 -> 139716867808448
	139716867808448 [label=AccumulateGrad]
	139716867808400 -> 139716867808160
	139716867808400 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	139716867808544 -> 139716867808400
	139716867808544 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (1, 150528)
mat1_sym_strides:             ()
mat2            :           None
mat2_sym_sizes  :  (150528, 300)
mat2_sym_strides:    (1, 150528)"]
	139716867808736 -> 139716867808544
	139717093331072 [label="layer1.bias
 (300)" fillcolor=lightblue]
	139717093331072 -> 139716867808736
	139716867808736 [label=AccumulateGrad]
	139716867808688 -> 139716867808544
	139716867808688 [label=TBackward0]
	139716867808784 -> 139716867808688
	139716878490080 [label="layer1.weight
 (300, 150528)" fillcolor=lightblue]
	139716878490080 -> 139716867808784
	139716867808784 [label=AccumulateGrad]
	139716867808112 -> 139716867808160
	139716867808112 [label=TBackward0]
	139716867808832 -> 139716867808112
	139717093330592 [label="layer2.weight
 (300, 300)" fillcolor=lightblue]
	139717093330592 -> 139716867808832
	139716867808832 [label=AccumulateGrad]
	139716867808256 -> 139716867808016
	139716867808256 [label=TBackward0]
	139716867808640 -> 139716867808256
	139716867885712 [label="output_layer.weight
 (11, 300)" fillcolor=lightblue]
	139716867885712 -> 139716867808640
	139716867808640 [label=AccumulateGrad]
	139716867808016 -> 139717091823264
}
